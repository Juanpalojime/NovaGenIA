# NovaGenIA - Gu√≠as de Uso de Nuevas Funcionalidades

## üìö Tabla de Contenidos

1. [Real-time Generation Progress](#1-real-time-generation-progress)
2. [Multi-GPU Support](#2-multi-gpu-support)
3. [Advanced LoRA Management](#3-advanced-lora-management)
4. [Community Model Hub](#4-community-model-hub)
5. [PWA / Mobile App](#5-pwa--mobile-app)

---

## 1. Real-time Generation Progress

### ¬øQu√© es?
Sistema de progreso en tiempo real que muestra el avance de la generaci√≥n de im√°genes step-by-step con WebSockets.

### Caracter√≠sticas
- ‚úÖ Progreso en tiempo real (0-100%)
- ‚úÖ N√∫mero de step actual y total
- ‚úÖ Tiempo transcurrido
- ‚úÖ Tiempo estimado restante (ETA)
- ‚úÖ Indicador de stage (initializing, generating, saving)
- ‚úÖ Reconexi√≥n autom√°tica

### C√≥mo Usar

#### Desde el Frontend
El progreso se muestra autom√°ticamente al generar im√°genes en Creative Dashboard o Pro Studio.

#### API WebSocket
```javascript
// Conectar al WebSocket
const ws = new WebSocket('ws://localhost:7860/ws/progress/JOB_ID')

// Escuchar eventos
ws.onmessage = (event) => {
  const data = JSON.parse(event.data)
  console.log(data)
  // {
  //   type: 'step_complete',
  //   step: 15,
  //   total_steps: 30,
  //   progress: 50,
  //   elapsed: 12.5,
  //   eta: 12.5
  // }
}
```

#### Eventos Disponibles
- `stage_change`: Cambio de etapa (initializing ‚Üí generating ‚Üí saving)
- `step_complete`: Completado un step del pipeline
- `generation_complete`: Generaci√≥n finalizada
- `error`: Error durante la generaci√≥n

---

## 2. Multi-GPU Support

### ¬øQu√© es?
Sistema de balanceo de carga que distribuye trabajos de generaci√≥n entre m√∫ltiples GPUs autom√°ticamente.

### Caracter√≠sticas
- ‚úÖ Detecci√≥n autom√°tica de GPUs
- ‚úÖ Balanceo de carga inteligente
- ‚úÖ Monitoreo de VRAM en tiempo real
- ‚úÖ Cola de trabajos con prioridades
- ‚úÖ Estad√≠sticas por GPU

### C√≥mo Usar

#### Ver Estado de GPUs
1. Ir a **Settings** ‚Üí **GPU Status**
2. Ver informaci√≥n de cada GPU:
   - Nombre y ID
   - VRAM total, usado, libre
   - Utilizaci√≥n (%)
   - Jobs activos

#### API
```bash
# Ver estado de todas las GPUs
curl http://localhost:7860/gpu/status
```

Respuesta:
```json
{
  "available": true,
  "count": 2,
  "gpus": [
    {
      "id": 0,
      "name": "NVIDIA RTX 4090",
      "total_vram_gb": 24.0,
      "allocated_vram_gb": 8.5,
      "free_vram_gb": 15.5,
      "utilization": 35.4,
      "active_jobs": 1
    }
  ]
}
```

### C√≥mo Funciona
1. El sistema detecta todas las GPUs CUDA disponibles
2. Al recibir un trabajo, selecciona la GPU con:
   - Menos jobs activos
   - Mayor VRAM disponible
3. Asigna el trabajo y actualiza estad√≠sticas
4. Al completar, libera la GPU

---

## 3. Advanced LoRA Management

### ¬øQu√© es?
Sistema avanzado para gestionar, combinar y aplicar m√∫ltiples LoRAs con pesos configurables.

### Caracter√≠sticas
- ‚úÖ Escaneo autom√°tico de LoRAs
- ‚úÖ Metadata con tags y trigger words
- ‚úÖ B√∫squeda y filtrado
- ‚úÖ Combinaci√≥n de m√∫ltiples LoRAs
- ‚úÖ Pesos configurables (0.0 - 2.0)
- ‚úÖ Preview de LoRAs

### C√≥mo Usar

#### Agregar LoRAs
1. Colocar archivos `.safetensors`, `.pt` o `.ckpt` en `models/loras/`
2. (Opcional) Crear archivo de metadata `nombre_lora.json`:

```json
{
  "name": "Mi LoRA Personalizado",
  "description": "Estilo art√≠stico √∫nico",
  "tags": ["artistic", "anime", "custom"],
  "trigger_words": ["artlora", "unique style"],
  "author": "Tu Nombre",
  "version": "1.0"
}
```

#### Usar en Pro Studio
1. Ir a **Pro Studio** ‚Üí **LoRA Studio** tab
2. **Browse LoRAs**: Ver todos los LoRAs disponibles
   - Buscar por nombre
   - Filtrar por tags
   - Click en `+` para agregar
3. **Mix LoRAs**: Combinar m√∫ltiples LoRAs
   - Ajustar peso con slider (0.0 - 2.0)
   - Ver peso total combinado
   - Remover LoRAs individuales

#### API
```bash
# Listar todos los LoRAs
curl http://localhost:7860/loras

# Buscar LoRAs
curl -X POST http://localhost:7860/loras/search \
  -H "Content-Type: application/json" \
  -d '{"query": "anime", "tags": ["artistic"]}'
```

### Tips de Uso
- **Peso 1.0**: Fuerza completa del LoRA
- **Peso 0.5-0.8**: Influencia sutil
- **Peso >1.0**: Efecto exagerado
- **Combinar 2-3 LoRAs**: Mejores resultados
- **Usar trigger words**: En el prompt para activar el LoRA

---

## 4. Community Model Hub

### ¬øQu√© es?
Integraci√≥n con Hugging Face Hub para buscar, descargar y gestionar modelos de la comunidad.

### Caracter√≠sticas
- ‚úÖ B√∫squeda en Hugging Face Hub
- ‚úÖ Filtros por tipo (checkpoint, LoRA, VAE, ControlNet)
- ‚úÖ Descarga con progreso
- ‚úÖ Gesti√≥n de modelos instalados
- ‚úÖ Informaci√≥n de downloads y likes

### C√≥mo Usar

#### Buscar Modelos
1. Ir a **Model Hub** (ruta `/hub`)
2. Seleccionar tipo de modelo
3. Escribir b√∫squeda
4. Click en **Search**

#### Descargar Modelos
1. En resultados de b√∫squeda, click en **Download**
2. Ver progreso de descarga
3. Modelo aparece en tab **Installed**

#### Gestionar Instalados
1. Tab **Installed**
2. Ver todos los modelos descargados
3. Click en üóëÔ∏è para eliminar

#### API
```bash
# Buscar modelos
curl -X POST http://localhost:7860/hub/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "stable diffusion xl",
    "model_type": "checkpoint",
    "limit": 20
  }'

# Descargar modelo
curl -X POST http://localhost:7860/hub/download \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "stabilityai/stable-diffusion-xl-base-1.0",
    "model_type": "checkpoint"
  }'

# Ver instalados
curl http://localhost:7860/hub/installed
```

### Tipos de Modelos
- **Checkpoints**: Modelos base completos
- **LoRAs**: Adaptadores de estilo
- **VAEs**: Variational Autoencoders
- **ControlNets**: Control de composici√≥n

---

## 5. PWA / Mobile App

### ¬øQu√© es?
Progressive Web App que permite instalar NovaGenIA como aplicaci√≥n nativa en dispositivos m√≥viles y desktop.

### Caracter√≠sticas
- ‚úÖ Instalable como app nativa
- ‚úÖ Soporte offline b√°sico
- ‚úÖ Icono en home screen
- ‚úÖ Splash screen
- ‚úÖ Funciona sin conexi√≥n (recursos cacheados)

### C√≥mo Instalar

#### En Chrome/Edge (Desktop)
1. Abrir NovaGenIA en navegador
2. Click en icono de instalaci√≥n en barra de direcciones
3. Click en **Instalar**

#### En Chrome (Android)
1. Abrir NovaGenIA en Chrome
2. Men√∫ ‚Üí **Agregar a pantalla de inicio**
3. Confirmar instalaci√≥n

#### En Safari (iOS)
1. Abrir NovaGenIA en Safari
2. Bot√≥n compartir ‚Üí **Agregar a pantalla de inicio**
3. Confirmar

### Funcionalidades Offline
- ‚úÖ Interfaz completa disponible
- ‚úÖ Recursos est√°ticos cacheados
- ‚ö†Ô∏è Generaci√≥n requiere conexi√≥n (backend)

### Verificar PWA
```javascript
// En DevTools Console
if ('serviceWorker' in navigator) {
  navigator.serviceWorker.getRegistrations()
    .then(regs => console.log('Service Workers:', regs))
}
```

---

## üîß Troubleshooting

### WebSocket no conecta
- Verificar que el servidor est√© corriendo
- Revisar URL del WebSocket (ws:// o wss://)
- Verificar CORS settings

### GPU no detectada
- Verificar instalaci√≥n de CUDA
- Ejecutar: `python -c "import torch; print(torch.cuda.is_available())"`
- Revisar drivers de GPU

### LoRAs no aparecen
- Verificar que est√©n en `models/loras/`
- Extensiones soportadas: `.safetensors`, `.pt`, `.ckpt`
- Reiniciar servidor para re-escanear

### Model Hub no busca
- Verificar conexi√≥n a internet
- Instalar: `pip install huggingface_hub`
- Verificar que HuggingFace est√© accesible

### PWA no se instala
- Usar HTTPS (o localhost)
- Verificar que `manifest.json` est√© accesible
- Revisar DevTools ‚Üí Application ‚Üí Manifest

---

## üìû Soporte

Para m√°s ayuda:
- Ver `INSTALLATION_GUIDE.md` para setup
- Ver `COMPLETION_SUMMARY.md` para resumen t√©cnico
- Revisar logs del servidor para errores
- Abrir issue en GitHub

---

**Versi√≥n**: 2.0.0  
**√öltima actualizaci√≥n**: Diciembre 2025
