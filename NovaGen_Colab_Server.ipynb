{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a70a1967",
            "metadata": {},
            "source": [
                "# üöÄ NovaGen AI - Backend Server (Repo Edition)\n",
                "Este notebook automatizado despliega el backend de NovaGen AI en Google Colab T4.\n",
                "\n",
                "- üß† **Gesti√≥n de Modelos**: Descarga Juggernaut-XL v9 y LoRAs personalizados.\n",
                "- üì• **Clonado Autom√°tico**: Obtiene la √∫ltima versi√≥n de `Juanpalojime/NovaGenIA`.\n",
                "- ‚ö° **GPU T4**: Verificaci√≥n y optimizaci√≥n de entorno.\n",
                "- üåê **Acceso Remoto**: T√∫nel Ngrok seguro.\n",
                "- üß† **Gesti√≥n de Modelos**: Descarga SDXL 1.0 y LoRAs personalizados.\n",
                "- üîå **API FastAPI**: Endpoints para generaci√≥n de im√°genes y entrenamiento."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d5e2de3e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 1. Inicializaci√≥n del Entorno (Clone & Install)\n",
                "import os\n",
                "import subprocess\n",
                "import sys\n",
                "\n",
                "print(\"üöÄ Iniciando secuencia de arranque...\")\n",
                "\n",
                "# 1. Verificar GPU\n",
                "import torch\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"‚úÖ GPU Detectada: {torch.cuda.get_device_name(0)}\")\n",
                "    # Force reinstall for xformers compatibility if needed\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è ADVERTENCIA: GPU no detectada. Ve a 'Entorno de ejecuci√≥n' > 'Cambiar tipo' > 'T4 GPU'.\")\n",
                "\n",
                "# 2. Clonar/Actualizar Repositorio\n",
                "REPO_URL = \"https://github.com/Juanpalojime/NovaGenIA.git\"\n",
                "REPO_NAME = \"NovaGenIA\"\n",
                "\n",
                "if os.path.exists(REPO_NAME):\n",
                "    print(\"üîÑ Actualizando repositorio...\")\n",
                "    %cd {REPO_NAME}\n",
                "    !git pull\n",
                "    %cd ..\n",
                "else:\n",
                "    print(\"‚¨á Clonando repositorio...\")\n",
                "    !git clone {REPO_URL}\n",
                "\n",
                "# 3. Instalar Dependencias\n",
                "print(\"‚è≥ Instalando dependencias de Python (aprox. 2 min)...\")\n",
                "!pip install -r {REPO_NAME}/requirements.txt -q\n",
                "!pip install pyngrok nest_asyncio huggingface_hub websockets -q\n",
                "\n",
                "print(\"‚úÖ Entorno preparado.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "drive_mount_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 1.5 Mount Google Drive (Optional)\n",
                "from google.colab import drive\n",
                "import os\n",
                "\n",
                "print(\"üìÇ Mounting Google Drive...\")\n",
                "try:\n",
                "    drive.mount('/content/drive')\n",
                "    print(\"‚úÖ Drive mounted at /content/drive\")\n",
                "    \n",
                "    # Create outputs folder if not exists\n",
                "    drive_output_path = \"/content/drive/MyDrive/NovaGen_Outputs\"\n",
                "    os.makedirs(drive_output_path, exist_ok=True)\n",
                "    print(f\"‚úÖ Output folder ready: {drive_output_path}\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ö†Ô∏è Drive mount skipped or failed: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "frontend_build_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 1.8 Build Frontend (Install Node.js & Build React App)\n",
                "import os\n",
                "\n",
                "print(\"üì¶ Installing Node.js 18...\")\n",
                "!curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash - > /dev/null\n",
                "!sudo apt-get install -y nodejs > /dev/null\n",
                "\n",
                "print(\"üìÇ Building Frontend App...\")\n",
                "frontend_dir = f\"{REPO_NAME}/app\"\n",
                "if os.path.exists(frontend_dir):\n",
                "    %cd {frontend_dir}\n",
                "    print(\"   installing npm packages...\")\n",
                "    !npm install > /dev/null 2>&1\n",
                "    print(\"   building production bundle...\")\n",
                "    !npm run build\n",
                "    %cd ../..\n",
                "    print(\"‚úÖ Frontend Build Complete!\")\n",
                "else:\n",
                "    print(f\"‚ùå Frontend directory not found at {frontend_dir}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "36a3e5ae",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 2. Configuraci√≥n de Credenciales (Ngrok, HuggingFace, CivitAI)\n",
                "from pyngrok import ngrok\n",
                "import os\n",
                "\n",
                "# @markdown ### Ngrok Setup\n",
                "# @markdown Token para t√∫nel p√∫blico (https://dashboard.ngrok.com):\n",
                "NGROK_AUTH_TOKEN = \"\" # @param {type:\"string\"}\n",
                "\n",
                "# @markdown ### Model Hubs Auth\n",
                "# @markdown Token de HuggingFace (Lectura) para descargar SDXL:\n",
                "HF_TOKEN = \"\" # @param {type:\"string\"}\n",
                "# @markdown API Key de CivitAI (Opcional para LoRAs restringidos):\n",
                "CIVITAI_API_KEY = \"\" # @param {type:\"string\"}\n",
                "\n",
                "# Configurar Ngrok\n",
                "if NGROK_AUTH_TOKEN:\n",
                "    # Limpieza autom√°tica por si se pega el comando completo\n",
                "    clean_token = NGROK_AUTH_TOKEN.replace(\"ngrok config add-authtoken \", \"\").strip()\n",
                "    ngrok.set_auth_token(clean_token)\n",
                "    print(f\"‚úÖ Ngrok configurado (Token: {clean_token[:4]}...{clean_token[-4:]})\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Ngrok Token no proporcionado. El t√∫nel podr√≠a fallar.\")\n",
                "\n",
                "# Guardar variables para uso en el sistema\n",
                "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
                "os.environ[\"CIVITAI_API_KEY\"] = CIVITAI_API_KEY\n",
                "\n",
                "if HF_TOKEN:\n",
                "    !huggingface-cli login --token {HF_TOKEN}\n",
                "    print(\"‚úÖ HuggingFace Login Exitoso.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5951dd65",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 3. Descarga de Modelos (Juggernaut-XL v9 & LoRAs)\n",
                "import os\n",
                "\n",
                "MODELS_DIR = f\"{REPO_NAME}/models/checkpoints\"\n",
                "LORAS_DIR = f\"{REPO_NAME}/models/loras\"\n",
                "os.makedirs(MODELS_DIR, exist_ok=True)\n",
                "os.makedirs(LORAS_DIR, exist_ok=True)\n",
                "\n",
                "print(\"üì• Comenzando descarga de modelos...\")\n",
                "\n",
                "# 1. Juggernaut-XL v9 RunDiffusion Photo v2 desde CivitAI\n",
                "print(\"   - Descargando Juggernaut-XL v9 RunDiffusion Photo v2...\")\n",
                "MODEL_FILENAME = \"Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors\"\n",
                "MODEL_PATH = os.path.join(MODELS_DIR, MODEL_FILENAME)\n",
                "\n",
                "if not os.path.exists(MODEL_PATH):\n",
                "    # URL de CivitAI para Juggernaut-XL v9\n",
                "    # Nota: Esta es la URL directa del modelo. Si requiere API key, agr√©gala como par√°metro\n",
                "    MODEL_URL = \"https://civitai.com/api/download/models/456194\"\n",
                "    \n",
                "    if os.environ.get(\"CIVITAI_API_KEY\"):\n",
                "        MODEL_URL = f\"{MODEL_URL}?token={os.environ['CIVITAI_API_KEY']}\"\n",
                "    \n",
                "    print(f\"     ‚¨á Descargando {MODEL_FILENAME} (~6.5 GB, puede tardar 5-10 min)...\")\n",
                "    !wget -O {MODEL_PATH} \"{MODEL_URL}\" --progress=bar:force:noscroll\n",
                "    print(f\"     ‚úÖ {MODEL_FILENAME} descargado exitosamente.\")\n",
                "else:\n",
                "    print(f\"     ‚úÖ {MODEL_FILENAME} ya existe.\")\n",
                "\n",
                "# 2. Descargar LoRAs de CivitAI\n",
                "loras_to_download = [\n",
                "    # { \"name\": \"pixel_art_xl.safetensors\", \"url\": \"https://civitai.com/api/download/models/123456\" },\n",
                "    # A√±ade tus URLs aqu√≠\n",
                "]\n",
                "\n",
                "print(f\"   - Descargando {len(loras_to_download)} LoRAs adicionales...\")\n",
                "for lora in loras_to_download:\n",
                "    name = lora['name']\n",
                "    url = lora['url']\n",
                "    path = os.path.join(LORAS_DIR, name)\n",
                "    \n",
                "    if not os.path.exists(path):\n",
                "        if os.environ.get(\"CIVITAI_API_KEY\"):\n",
                "            url = f\"{url}?token={os.environ['CIVITAI_API_KEY']}\"\n",
                "        \n",
                "        print(f\"     ‚¨á Descargando {name}...\")\n",
                "        !wget -O {path} \"{url}\"\n",
                "    else:\n",
                "        print(f\"     ‚úÖ {name} ya existe.\")\n",
                "\n",
                "# 3. Descargar Modelo FaceSwap (InsightFace)\n",
                "print(\"   - Descargando modelo FaceSwap (inswapper_128.onnx)...\")\n",
                "FACESWAP_DIR = f\"{REPO_NAME}/models/insightface\"\n",
                "os.makedirs(FACESWAP_DIR, exist_ok=True)\n",
                "SWAP_MODEL_URL = \"https://huggingface.co/ezioruan/inswapper_128.onnx/resolve/main/inswapper_128.onnx\"\n",
                "SWAP_MODEL_PATH = os.path.join(FACESWAP_DIR, \"inswapper_128.onnx\")\n",
                "\n",
                "if not os.path.exists(SWAP_MODEL_PATH):\n",
                "    print(f\"     ‚¨á Descargando inswapper_128.onnx...\")\n",
                "    !wget -O {SWAP_MODEL_PATH} \"{SWAP_MODEL_URL}\" --progress=bar:force:noscroll\n",
                "    print(f\"     ‚úÖ inswapper_128.onnx descargado.\")\n",
                "else:\n",
                "    print(f\"     ‚úÖ inswapper_128.onnx ya existe.\")\n",
                "\n",
                "print(\"üèÅ Descargas completadas.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5951dd65",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 4. INICIAR BACKEND (FastAPI + Uvicorn)\n",
                "import nest_asyncio\n",
                "import time\n",
                "from pyngrok import ngrok\n",
                "from pyngrok.exception import PyngrokNgrokError\n",
                "import sys\n",
                "\n",
                "nest_asyncio.apply()\n",
                "\n",
                "print(\"üîÑ Limpiando procesos anteriores...\")\n",
                "!pkill -f uvicorn\n",
                "ngrok.kill()\n",
                "time.sleep(3) # Esperar a que se cierren completamente\n",
                "\n",
                "# Iniciar T√∫nel\n",
                "PORT = 7860\n",
                "try:\n",
                "    print(\"üîå Conectando Ngrok...\")\n",
                "    tunnel = ngrok.connect(PORT)\n",
                "    public_url = tunnel.public_url\n",
                "\n",
                "    print(\"=\"*50)\n",
                "    print(f\"üîó PUBLIC API URL: \\033[96m{public_url}\\033[0m\")\n",
                "    print(\"=\"*50)\n",
                "    print(\"üëâ Copia esta URL y p√©gala en NovaGen > Settings > Connections\")\n",
                "    print(\"üëâ El servidor iniciar√° a continuaci√≥n (Logs abajo)...\\n\")\n",
                "    print(\"‚ö†Ô∏è NOTA: Como el frontend est√° servido en / (root), tu URL p√∫blica muestra la App directamente.\")\n",
                "\n",
                "    # Cambiar al directorio del repo para ejecuci√≥n\n",
                "    %cd {REPO_NAME}\n",
                "    \n",
                "    # Patch para correr tests si se desea (opcional)\n",
                "    # !pytest tests/\n",
                "\n",
                "    # Iniciar Servidor (Bloqueante)\n",
                "    !python server.py\n",
                "except PyngrokNgrokError as e:\n",
                "    print(\"\\n‚ùå ERROR DE NGROK:\")\n",
                "    if \"ERR_NGROK_108\" in str(e):\n",
                "        print(\"‚ö†Ô∏è Tu cuenta gratuita de Ngrok tiene una sesi√≥n ya activa.\")\n",
                "        print(\"üëâ Ve a https://dashboard.ngrok.com/agents y elimina la sesi√≥n existente.\")\n",
                "    else:\n",
                "        print(f\"Detalles: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}